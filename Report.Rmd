---
title: "Report"
author: "Kang"
date: '2022-11-14'
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

# Introduction

The aims of this study are twofold: 
(1) methodology for the new paradigm (namely data-driven research): how to apply big data in ecosystem services / environmental economic research; 
(2) to solve some practical problems, e.g., accurately estimate the ecosystem culture value of national parks, the impact of COVID-19 on tourism, how the number of visitors will change in the future under different scenarios, etc. 

Before figuring out the specific science question of this research, those are what I have done: 
(1) explore the data, e.g., the general description of the data, the relationship between the number of visitors and some factors like weather; 
(2) trying to visualize the GIS data; 
(3) trying to estimate the total travel cost of the visitors. 
In the following sections, I will talk about the methods (which are very simple for now) and the results (which are also very simple for now). I will also talk about challenges (like data gap) and future plan. 

# Methods and Results 

## General description and impact factors 

Many details and some summary information have been given in Agoop's README file (namely *Agoop_point_data_specification.pdf*). I checked the raw data for the completeness of each variables (namely each "column" in the data), and the pattern of each variables (e.g., the ratio of male and female visitors). Here I will not give the details of the raw data check, but I will do more data check according to research question if needed. 

I then summarized the raw data on a daily basis. In the summary data, each row shows the number of the visitors for that day (the number of unique "dailyid"). Then I added the information of daily weather, and holiday/weekend into the summary data. For the details of the raw data (like data source), please refer to the *Codebook* section of *README.md* file of the GitHub repository *Fujisan*. The summary data looks like this (show the first 6 rows of the data): 

```{r}
day.mobile %>% 
  head() %>% 
  select(date, num, wthr, wknd_hol) %>% 
  rename(
    "visitor num" = num, "weather" = wthr, "weekend/holiday" = wknd_hol
  ) %>%
  knitr::kable()
```

And that is the change of visitors number: 

```{r}
ggplot(day.mobile) + 
  geom_col(aes(date, num)) + 
  facet_wrap(.~ year, scales = "free")
```

So, does the pattern have anything to do with some factors like weather or distance? 
Firstly, let's see the relationship between visitors number and weekday/weekend/holiday. 

```{r}
ggplot(day.mobile) + 
  geom_col(aes(date, num, fill = wknd_hol)) + 
  facet_wrap(.~ year, scales = "free")
```

Then summary them by box plots: 

```{r}
ggplot(day.mobile) + 
  geom_boxplot(aes(wknd_hol, num)) + 
  facet_wrap(.~ year, scales = "free")
```

As we might expected with intuition, that weekend and holiday have more visitors than weekday. A further statistical test is needed to confirm that conclusion. 

Then, the visitors number and weather. It should be noted that, the raw daily weather data from Japan Meteorological Agency gives the weather in three periods in one day, namely 0 am ~ 9 am, 9 am ~ 3 pm, 3 pm ~ 12 pm. Sometimes weather varies in one day (e.g., sunny in the morning while rainy in the afternoon). Since rainy days might affect people's decision about mountain climbing, I added up the weather of one day by following rules: if the weather of any period in one day is "rainy", then the weather is denoted as "rain"; instead, it will be noted as "no rain". For the result, without surprise, the visitor number in the days without rain is higher than that of rainy days. A further statistical analysis is needed to confirm if the difference is significant. 

```{r}
ggplot(day.mobile) + 
  geom_col(aes(date, num, fill = wthr)) + 
  facet_wrap(.~ year, scales = "free")
# bug: can also analyze the relationship between stay duration and weather, suppose that when weather is good, the duration of stay should be longer
ggplot(day.mobile) + 
  geom_boxplot(aes(wthr, num)) + 
  facet_wrap(.~ year, scales = "free")
```

Then, how about distance? I summarized the visitor number from different prefecture in this two summers. The summary data looks like this (show the first 6 rows, ordered by visitor number): 

```{r}
day.pref.mobile %>% 
    group_by(home_prefcode) %>% 
    summarise(num = sum(num)) %>% 
    ungroup() %>% 
    arrange(-num) %>% 
    head() %>% 
    left_join(pref.city.code %>% select(prefcode, prefname) %>% distinct(), 
              by = c("home_prefcode" = "prefcode")) %>% 
    select(prefname, num) %>% 
    knitr::kable()
```

If we take a look at the top 20 prefectures with more vistors, we might suppose that the closer the source location is, the more visitors ... 

```{r cars}
day.pref.mobile %>% 
  group_by(home_prefcode) %>% 
  summarise(num = sum(num)) %>% 
  ungroup() %>% 
  arrange(-num) %>% 
  left_join(pref.city.code %>% select(prefcode, prefname) %>% distinct(), 
            by = c("home_prefcode" = "prefcode")) %>% 
  # pick the top 20 to plot 
  head(20) %>% 
  ggplot() + 
  geom_col(aes(reorder(prefname, num), num)) + 
  coord_flip()
```

or, it might have something to do with the time and money the visitors have to spent on the tour. So, I add the per capital cost of the visitors from different regions (which is from the previous report of our project, *我が国における自然環境施策への効果的な資源動員に向けた研究研究報告書*). Here shows the per caipital cost of different regions: 

```{r}
cost.list %>% 
  select(pref, cost) %>% 
  rename(region = pref) %>% 
  knitr::kable()
```

And I aggregated the number of each prefecture according to the regions of this per capital cost data, and visualized the relationship between visitor number and per caipital cost of each region: 

```{r}
mob.pref.idnum %>% 
    subset(!is.na(region)) %>% 
    group_by(pref_agg, cost) %>% 
    summarise(num = sum(num)) %>% 
    ungroup() %>% 
    ggplot() + 
    geom_point(aes(cost, num)) + 
    geom_text(aes(x = cost, y = num + 200, label = pref_agg))
```

The plot indicates that as a general trend, the visitor number decreases with the growing cost. 

To sum up, in this section, I explored the mobilization data, showing the change of visitor number on a daily basis, the relationship between daily visitor number and some factors (weekend/holiday, weather, distance/cost). However, it is just a primary analysis: 

(1) statistical analysis (like correlation analysis or some other more complex model) is needed to confirm the correlation between visitor number and the impact factors; 

(2) need to consider other response variables (e.g., the stay time of visitors) and other explanatory variables (e.g. travel time); 

(3) need to think about the summary method of daily weather again (it is possible that the weather between 0 am ~ 9 am is less important in people's mountain climbing decision compared to 9 am ~ 3 pm weather and 3 pm ~ 12 pm weather); 

(4) need to do analysis at other scale (the analysis on a daily basis is shown in this section, but the analysis on a hourly basis has not been done yet); 

(5) the daily visitor number and the number from different prefecture is currently directly calculated out of the raw data, but it should be adjusted based on other parameters (e.g., a simple example, if only 90% people use smart phone in a prefecture, then the daily visitor number would make more sense if divided by 0.9); 

(6) another key problem about daily visitor number - the geographical range of Agoop raw data is larger than the extent of Fujisan mountain, so in fact I should crop the data before the analysis (so I need the layer of the Fujisan mountain extent first). 

## GIS analysis

In this section, I just turned the raw data into simple feature class (GIS data class of sf package), then I cropped the geographical range of the data to keep the mobilization records near the Fujisan mountain. Here is all the records left (the following figure). Each red translucent dots represent one mobilization record, so theoretically the darker the color means there are more records. However, since there are so many records, it is not clear to make a map like this. So a better ideas is to calculate the number of record in each area/route before make a map, or to slice the records into time pieces (e.g., the time slice of 0 am ~ 1 am, 1 am ~ 2 am, etc.) and make maps. 

![Mapping the records](ProcData/Mobile_path_raw.png)

# Next step

The key issue for next step is to find out the specific question for this research. I do more literature reading and review for that. 

# Appendix

Here I would like to talk about how the folders and files are organized when I am doing a project. 

I usually have 3 folders: 
(1) *RawData* folder to store the raw data, and the explanation of the raw data please see the README.md file outside the folders; 
(2) *ProcData* folder to store the files generated by code (e.g., the figures, results); 
(3) *File* folder to store other files like middle report, draft, etc, but I do not sync this file to GitHub so you dont' need to worry about it. 

Then, outside the folders, there usually some types of files: 
(1) Code: files end with ".R", and there are usually a "Main.R" file to link or to organize the other code file; 
(2) README.md: the introduction of the project, the information about data source and data explanation; 
(3) Other RMarkdown files: for example, "Diary.Rmd" is used to write down what I have done and my thoughts during the analysis (it can be messy), "Report.Rmd" is used to generate middle report for the analysis (this report is generated by it). 
